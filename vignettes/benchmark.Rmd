---
title: "Runtime Comparison of Critical Pairing Algorithms"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Runtime Comparison of Critical Pairing Algorithms}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  %\VignetteDepends{dplyr,tidyr,ggplot2,bench}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This vignette compares the runtimes and memory allocations of the multi-pass and single-pass algorithms for pairing critical points.
Several tidyverse packages are used to post-process the benchmark results:

```{r setup}
library(rgph)
library(dplyr)
library(tidyr)
library(ggplot2)
```

## The running example

To illustrate, compare the results of the two algorithms on the running example from Tu &al (2018):

```{r example calculation}
ex_file <- system.file("extdata", "running_example.txt", package = "rgph")
ex_reeb <- read_reeb_graph(ex_file)
( ex_multi <- reeb_graph_pairs(ex_reeb, method = "multi_pass") )
( ex_single <- reeb_graph_pairs(ex_reeb, method = "single_pass") )
all.equal(ex_multi, ex_single)
```

We expect the resulting data frames to be equivalent, but the output contains the attributes `method` and `elapsed_time` that we expect to be different.
If we ignore attributes, then we find the results to agree:

```{r example validation}
all.equal(ex_multi, ex_single, check.attributes = FALSE)
```

For this reason, and to avoid incurring additional runtime costs, we omit the default check in the benchmarking run:

```{r example benchmark}
bench::mark(
  multi = reeb_graph_pairs(ex_reeb, method = "multi_pass"),
  single = reeb_graph_pairs(ex_reeb, method = "single_pass"),
  check = FALSE
)
```

The R bindings are equivalent; while total runtimes will be higher than when comparing the Java programs directly, the differences between them should be the same.
Indeed, the allocated memory is exactly the same.
However, the single-pass algorithm---Propagate and Pair---is a marginal improvement over the multiple-pass merge pairing algorithm.

## A more complex case



```{r flower}
flower_file <- system.file("extdata", "flower_reebgraph.txt", package = "rgph")
flower_reeb <- read_reeb_graph(flower_file)
bench::mark(
  multi = reeb_graph_pairs(flower_reeb, method = "multi_pass"),
  single = reeb_graph_pairs(flower_reeb, method = "single_pass"),
  check = FALSE
)
```



## How performance and improvement scale



```{r random (split) trees}
# collect split tree Reeb graphs
tree_files <- vapply(
  c(
    `10` = "10_tree_iterations.txt",
    `100` = "100_tree_iterations.txt",
    `1000` = "1000_tree_iterations.txt"
  ),
  function(f) system.file("extdata", f, package = "rgph"),
  ""
)
tree_reebs <- lapply(tree_files, read_reeb_graph)
tree_reebs <- lapply(tree_reebs, function(rg) { rg$values <- -rg$values; rg })
# aggregate benchmark comparisons
tree_bench <- tibble()
for (i in seq_along(tree_reebs)) {
  bm <- bench::mark(
    multi = reeb_graph_pairs(tree_reebs[[i]], method = "multi_pass"),
    single = reeb_graph_pairs(tree_reebs[[i]], method = "single_pass"),
    check = FALSE
  )
  bm <- transmute(
    bm,
    method = as.character(expression),
    n_itr, time, memory
  )
  bm <- relocate(mutate(bm, size = as.integer(names(tree_files)[[i]])), size)
  tree_bench <- bind_rows(tree_bench, bm)
}
# plot runtime results
tree_bench %>%
  select(size, method, time) %>%
  unnest(time) %>%
  ggplot(aes(x = as.factor(size), y = time * 1e6)) +
  geom_boxplot(aes(color = method, shape = method)) +
  scale_y_continuous(
    transform = "log1p",
    labels = scales::label_number(suffix = "Âµs")
  ) +
  labs(x = "tree size", y = "run time")
```
